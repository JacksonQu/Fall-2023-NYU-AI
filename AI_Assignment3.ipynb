{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytube import YouTube\n",
    "from filterpy.kalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = './videos'\n",
    "IMAGE_DIR = './images'\n",
    "DETECT_DIR = './detections'\n",
    "KF_DIR = './kfs'\n",
    "OUTPUT_DIR = './outputs'\n",
    "\n",
    "DATASET_SRC = './Database1/Database1'\n",
    "DATASET_DST = './datasets'\n",
    "\n",
    "VIDEO_URLS = ['https://www.youtube.com/watch?v=DhmZ6W1UAv4', 'https://www.youtube.com/watch?v=YrydHPwRelI']\n",
    "VIDEO_FILENAMES = ['video1.mp4', 'video2.mp4']\n",
    "\n",
    "# 1080p 30fps\n",
    "ITAG = 137\n",
    "\n",
    "TARGET = 'drone'\n",
    "TARGET_INDEX = '0'\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "FINE_TUNE_CONFIG = './custom.yaml'\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File video1.mp4 existed.\n",
      "File video2.mp4 existed.\n"
     ]
    }
   ],
   "source": [
    "# Download video\n",
    "if not os.path.exists(VIDEO_DIR):\n",
    "    os.mkdir(VIDEO_DIR)\n",
    "\n",
    "for i, URL in enumerate(VIDEO_URLS):\n",
    "    if os.path.exists(f'{VIDEO_DIR}/{VIDEO_FILENAMES[i]}'):\n",
    "        print(f'File {VIDEO_FILENAMES[i]} existed.')\n",
    "    else:\n",
    "        video = YouTube(URL)\n",
    "        stream = video.streams.get_by_itag(ITAG)\n",
    "        stream.download(filename=f'{VIDEO_DIR}/{VIDEO_FILENAMES[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file video1.mp4 is divided into 4941 frames.\n",
      "Video file video2.mp4 is divided into 15409 frames.\n"
     ]
    }
   ],
   "source": [
    "# Slice image\n",
    "if not os.path.exists(IMAGE_DIR):\n",
    "    os.mkdir(IMAGE_DIR)\n",
    "\n",
    "for FILE in VIDEO_FILENAMES:\n",
    "    prefix = FILE.split('.')[0]     # e.g: video1\n",
    "    video = cv2.VideoCapture(f'{VIDEO_DIR}/{FILE}')\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(f'{IMAGE_DIR}/{prefix}_{frame_count}.png', frame)\n",
    "        frame_count += 1\n",
    "    video.release()\n",
    "    print(f'Video file {FILE} is divided into {frame_count} frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading drone-yolo-detection.zip to /Resource/fisher_file/summer/acs/ai/hw3\n",
      "100%|████████████████████████████████████████| 157M/157M [57:45<00:00, 52.3kB/s]\n",
      "100%|████████████████████████████████████████| 157M/157M [57:45<00:00, 47.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download dataset and unzip\n",
    "!kaggle datasets download -d sshikamaru/drone-yolo-detection\n",
    "!unzip -q drone-yolo-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset and preprocess\n",
    "if not os.path.exists(DATASET_DST):\n",
    "    os.mkdir(DATASET_DST)\n",
    "    os.mkdir(f'{DATASET_DST}/images')\n",
    "    os.mkdir(f'{DATASET_DST}/labels')\n",
    "\n",
    "\n",
    "for filename in os.listdir(DATASET_SRC):\n",
    "    if filename.endswith('.txt'):\n",
    "        prefix = filename.split('.')[0]\n",
    "        shutil.copy(f'{DATASET_SRC}/{prefix}.txt', f'{DATASET_DST}/labels')\n",
    "        shutil.copy(f'{DATASET_SRC}/{prefix}.JPEG', f'{DATASET_DST}/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fisher/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2023-11-8 Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (Tesla V100-SXM2-32GB, 32511MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:07<00:00, 2.00MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Origin model\n",
    "model_origin = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16057, done.\u001b[K\n",
      "remote: Total 16057 (delta 0), reused 0 (delta 0), pack-reused 16057\u001b[K\n",
      "Receiving objects: 100% (16057/16057), 14.66 MiB | 1.89 MiB/s, done.\n",
      "Resolving deltas: 100% (11028/11028), done.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: gitpython>=3.1.30 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 5)) (3.1.40)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 6)) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 7)) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 8)) (4.8.1.78)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 9)) (10.1.0)\n",
      "Requirement already satisfied: psutil in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 13)) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2+cu117)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n",
      "Requirement already satisfied: ultralytics>=8.0.147 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 18)) (8.0.207)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 27)) (2.1.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 28)) (0.13.0)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from -r yolov5/requirements.txt (line 42)) (67.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (6.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.7.101)\n",
      "Requirement already satisfied: triton==2.0.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (8.5.0.96)\n",
      "Requirement already satisfied: jinja2 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.4.0.1)\n",
      "Requirement already satisfied: typing-extensions in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (11.7.99)\n",
      "Requirement already satisfied: wheel in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (0.38.4)\n",
      "Requirement already satisfied: cmake in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.26.4)\n",
      "Requirement already satisfied: lit in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (16.0.6)\n",
      "Requirement already satisfied: py-cpuinfo in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Resource/fisher_file/anaconda3/envs/jupyter/lib/python3.9/site-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Clone yolov5 repo and install requirements.txt\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%pip install -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom.yaml\n",
    "custom_data = {\n",
    "    'path': f'.{DATASET_DST}',\n",
    "    'train': f'images',\n",
    "    'val': f'images',\n",
    "    'names': {0: f'{TARGET}'}\n",
    "}\n",
    "\n",
    "with open(FINE_TUNE_CONFIG, 'w') as file:\n",
    "    yaml.dump(custom_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 15:26:45.722520: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-11 15:26:45.722571: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-11 15:26:45.722600: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (offline), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v7.0-240-g84ec8b5 Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (Tesla V100-SXM2-32GB, 32511MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Resource/fisher_file/summer/acs/ai/hw3/datasets/labels.cache...\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video17_295.JPEG: ignoring corrupt image/label: cannot identify image file '/Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video17_295.JPEG'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video19_1900.JPEG: ignoring corrupt image/label: cannot identify image file '/Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video19_1900.JPEG'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Resource/fisher_file/summer/acs/ai/hw3/datasets/labels.cache... 4\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video17_295.JPEG: ignoring corrupt image/label: cannot identify image file '/Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video17_295.JPEG'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video19_1900.JPEG: ignoring corrupt image/label: cannot identify image file '/Resource/fisher_file/summer/acs/ai/hw3/datasets/images/video19_1900.JPEG'\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.86 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to yolov5/runs/train/exp4/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/exp4\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4      3.58G    0.07682    0.01895          0          9        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4008       3340      0.463      0.457       0.42      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4       4.8G    0.05172     0.0124          0         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4008       3340      0.749       0.78      0.785      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4       4.8G    0.04591   0.009667          0         11        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4008       3340      0.731      0.773      0.796      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4       4.8G    0.04019   0.008199          0         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4008       3340      0.833      0.883      0.895      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4       4.8G    0.03901   0.007862          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4008       3340      0.819      0.871      0.883      0.439\n",
      "\n",
      "5 epochs completed in 0.063 hours.\n",
      "Optimizer stripped from yolov5/runs/train/exp4/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from yolov5/runs/train/exp4/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating yolov5/runs/train/exp4/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4008       3340      0.832      0.882      0.895      0.443\n",
      "Results saved to \u001b[1myolov5/runs/train/exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Fine tune\n",
    "!python yolov5/train.py --img 640 --epochs 5 --data custom.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fisher/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2023-11-8 Python-3.9.16 torch-2.0.1+cu117 CUDA:0 (Tesla V100-SXM2-32GB, 32511MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=f'./yolov5/runs/train/exp4/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(prefix: str):\n",
    "    def func(filename: str):\n",
    "        return f'{prefix}/{filename}'\n",
    "    return func\n",
    "\n",
    "imgs = list(map(concat(IMAGE_DIR), os.listdir(IMAGE_DIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(0, len(imgs), BATCH_SIZE):\n",
    "    result = model(imgs[i : i + BATCH_SIZE])\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = []\n",
    "\n",
    "for result in results:\n",
    "    frames = result.files\n",
    "    assert len(frames) == len(result)\n",
    "    for i in range(len(result)):\n",
    "        record = result.pandas().xyxy[i]\n",
    "        for _, row in record.iterrows():\n",
    "            prefix = frames[i].split('.')[0]    # e.g: video1_123\n",
    "            # Append\n",
    "            df_data.append([prefix, prefix[:6], prefix[7:], *row.to_list()])\n",
    "\n",
    "table = {'filename': str,\n",
    "         'video': str,\n",
    "         'frame': int,\n",
    "         'xmin': float,\n",
    "         'ymin': float,\n",
    "         'xmax': float,\n",
    "         'ymax': float,\n",
    "         'confidence': float,\n",
    "         'class': int,\n",
    "         'name': str}\n",
    "\n",
    "df = pd.DataFrame(columns=table.keys(), data=df_data).astype(table)\n",
    "df.to_csv('detection_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "video1_df = df[(df['video'] == 'video1') & (df['name'] == TARGET)].sort_values('frame')\n",
    "video2_df = df[(df['video'] == 'video2') & (df['name'] == TARGET)].sort_values('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_retangle(file_path: str, position: tuple, label: str, save_path: str):\n",
    "    img = cv2.imread(file_path)\n",
    "    cv2.rectangle(img, pt1=(int(position[0]), int(position[1])), pt2=(int(position[2]), int(position[3])), color=(0, 255, 0), thickness=2)\n",
    "    cv2.putText(img=img, text=label, org=(int(position[0]), int(position[1])), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "    cv2.imwrite(filename=save_path, img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DETECT_DIR):\n",
    "    os.mkdir(DETECT_DIR)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if row['name'] == TARGET:\n",
    "        draw_retangle(f'{IMAGE_DIR}/{row[\"filename\"]}.png', (row['xmin'], row['ymin'], row['xmax'], row['ymax']), label=row['name'], save_path=f'./{DETECT_DIR}/{row[\"filename\"]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_filter(df: pd.DataFrame, fps: float = 30.0) -> list:\n",
    "    # parameters\n",
    "    initial_x = (df.iloc[0]['xmin'] + df.iloc[0]['xmax']) / 2\n",
    "    initial_y = (df.iloc[0]['ymin'] + df.iloc[0]['ymax']) / 2\n",
    "    initial_velocity_x = 0.1\n",
    "    initial_velocity_y = 0.1\n",
    "    dt = 1.0 / fps\n",
    "    # kalman filter\n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    kf.x = np.array([initial_x, initial_y, initial_velocity_x, initial_velocity_y])\n",
    "    kf.H = np.array([[1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0]])\n",
    "    kf.F = np.array([[1, 0, dt, 0],\n",
    "                    [0, 1, 0, dt],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1]])\n",
    "    kf.Q *= 0.01\n",
    "    kf.R *= 0.1\n",
    "\n",
    "    trajectory = []\n",
    "    for _, row in df.iterrows():\n",
    "        x = (row['xmin'] + row['xmax']) / 2\n",
    "        y = (row['ymin'] + row['ymax']) / 2\n",
    "        measurement = np.array([x, y])\n",
    "        kf.predict()\n",
    "        kf.update(measurement)\n",
    "        prediction = kf.x[:2]\n",
    "        trajectory.append(prediction)\n",
    "    return trajectory\n",
    "\n",
    "\n",
    "def plot_trajectory(trajectory: list) -> None:\n",
    "    trajectory = np.array(trajectory)\n",
    "    plt.plot(trajectory[:, 0], trajectory[:, 1], marker='o', label='Trajectory')\n",
    "    plt.xlabel('X Coordinate')\n",
    "    plt.ylabel('Y Coordinate')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory1 = kalman_filter(video1_df)\n",
    "trajectory2 = kalman_filter(video2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point(file_path: str, positions: list, save_path: str):\n",
    "    img = cv2.imread(file_path)\n",
    "    for position in positions:\n",
    "        cv2.circle(img, (int(position[0]), int(position[1])), 2, (0, 0, 255), -1)\n",
    "    cv2.imwrite(filename=save_path, img=img)\n",
    "\n",
    "if not os.path.exists(KF_DIR):\n",
    "    os.mkdir(KF_DIR)\n",
    "\n",
    "kf1_counter = 0\n",
    "for _, row in video1_df.iterrows():\n",
    "    kf1_counter += 1\n",
    "    draw_point(f'{DETECT_DIR}/{row[\"filename\"]}.png', trajectory1[:kf1_counter], f'./{KF_DIR}/{row[\"filename\"]}.png')\n",
    "\n",
    "kf2_counter = 0\n",
    "for _, row in video2_df.iterrows():\n",
    "    kf2_counter += 1\n",
    "    draw_point(f'{DETECT_DIR}/{row[\"filename\"]}.png', trajectory2[:kf2_counter], f'./{KF_DIR}/{row[\"filename\"]}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_video(df: pd.DataFrame) -> None:\n",
    "    pending_videos = []\n",
    "    current_video = []\n",
    "    # group images\n",
    "    for i in range(len(df) - 1):\n",
    "        if df.iloc[i + 1]['frame'] - df.iloc[i]['frame'] < WINDOW_SIZE:\n",
    "            current_video.append(df.iloc[i]['filename'])\n",
    "        else:\n",
    "            if len(current_video) > WINDOW_SIZE:\n",
    "                pending_videos.append(copy.deepcopy(current_video))\n",
    "            current_video.clear()\n",
    "    # make video\n",
    "    for i, pending_video in enumerate(pending_videos):\n",
    "        frame = cv2.imread(f'{KF_DIR}/{pending_video[0]}.png')\n",
    "        h, w, c = frame.shape\n",
    "        video = cv2.VideoWriter(f'./{OUTPUT_DIR}/{df.iloc[0][\"video\"]}_{i}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (w, h))\n",
    "        for f in pending_video:\n",
    "            video.write(cv2.imread(f'{KF_DIR}/{f}.png'))\n",
    "        video.release()\n",
    "\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "mk_video(video1_df)\n",
    "mk_video(video2_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
